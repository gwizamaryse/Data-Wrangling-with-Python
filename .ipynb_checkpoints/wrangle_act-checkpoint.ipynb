{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle and Analyze Data\n",
    "# #WeRateDogs \n",
    "\n",
    "WeRateDogs is a twitter account that rates dogs. we are using data from their account for data wrangling course.<br>\n",
    "A project which is part of Udacity Data Analyst Nanodegree.\n",
    "\n",
    "#### Steps to Effective Data Wrangling are: \n",
    "1. We will first gather data from 3 differents sources using different methods\n",
    "2. Then Assess the data visually and programatically for quality and tidiness issues. \n",
    "3. And then we are going to resolve those issues. \n",
    "4. The last step is no longer data wrangling, we are going to analyze the data. Give insights and make vizualisations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering data\n",
    "We have 3 sources of data to gather for this analysis.\n",
    "1. twitter-archive-enhanced.csv, this file was already provided as a csv file. we are going to use pandas read_csv to import the file\n",
    "2. image_predictions.tsv by using request library to download it\n",
    "3. By using tweepy, extract data  from twitter API and store it in a file named tweet_json.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the library that we will need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt;plt.rcdefaults()\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing file 1: twitter-archive-enhanced.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>806242860592926720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-06 21:04:11 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>RT @dog_rates: This is Dave. He's currently in a predicament. Doesn't seem to mind tho. 12/10 someone assist Dave https://t.co/nfprKAXqwu</td>\n",
       "      <td>7.833346e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>2016-10-04 15:55:06 +0000</td>\n",
       "      <td>https://twitter.com/dog_rates/status/783334639985389568/photo/1,https://twitter.com/dog_rates/status/783334639985389568/photo/1,https://twitter.com/dog_rates/status/783334639985389568/photo/1,https://twitter.com/dog_rates/status/783334639985389568/photo/1,https://twitter.com/dog_rates/status/783334639985389568/photo/1,https://twitter.com/dog_rates/status/783334639985389568/photo/1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Dave</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>692041934689402880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-26 17:50:29 +0000</td>\n",
       "      <td>&lt;a href=\"http://vine.co\" rel=\"nofollow\"&gt;Vine - Make a Scene&lt;/a&gt;</td>\n",
       "      <td>This is Teddy. His head is too heavy. 13/10 (vid by @jooanrim) https://t.co/sRUpRpGZ3y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://vine.co/v/iiI3wmqXYmA</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Teddy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>838831947270979586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-06 19:21:35 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>RT @dog_rates: This is Riley. His owner put a donut pillow around him and he loves it so much he won't let anyone take it off. 13/10 https:…</td>\n",
       "      <td>7.838400e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>2016-10-06 01:23:05 +0000</td>\n",
       "      <td>https://twitter.com/dog_rates/status/783839966405230592/photo/1,https://twitter.com/dog_rates/status/783839966405230592/photo/1,https://twitter.com/dog_rates/status/783839966405230592/photo/1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Riley</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>819952236453363712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-13 17:00:21 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>This is Oliver. He has dreams of being a service puppo so he can help his owner. 13/10 selfless af\\n\\nmake it happen:\\nhttps://t.co/f5WMsx0a9K https://t.co/6lJz0DKZIb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.gofundme.com/servicedogoliver,https://twitter.com/dog_rates/status/819952236453363712/photo/1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>puppo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>683773439333797890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-03 22:14:26 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>This is Buddy. He's gaining strength. Currently an F4 tornado with wind speeds up to 260mph. Very devastating. 9/10 https://t.co/qipZbshNsR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/683773439333797890/photo/1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Buddy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "541   806242860592926720 NaN                    NaN                    \n",
       "1502  692041934689402880 NaN                    NaN                    \n",
       "286   838831947270979586 NaN                    NaN                    \n",
       "439   819952236453363712 NaN                    NaN                    \n",
       "1648  683773439333797890 NaN                    NaN                    \n",
       "\n",
       "                      timestamp  \\\n",
       "541   2016-12-06 21:04:11 +0000   \n",
       "1502  2016-01-26 17:50:29 +0000   \n",
       "286   2017-03-06 19:21:35 +0000   \n",
       "439   2017-01-13 17:00:21 +0000   \n",
       "1648  2016-01-03 22:14:26 +0000   \n",
       "\n",
       "                                                                                  source  \\\n",
       "541   <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "1502  <a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>                      \n",
       "286   <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "439   <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "1648  <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "\n",
       "                                                                                                                                                                        text  \\\n",
       "541   RT @dog_rates: This is Dave. He's currently in a predicament. Doesn't seem to mind tho. 12/10 someone assist Dave https://t.co/nfprKAXqwu                                \n",
       "1502  This is Teddy. His head is too heavy. 13/10 (vid by @jooanrim) https://t.co/sRUpRpGZ3y                                                                                   \n",
       "286   RT @dog_rates: This is Riley. His owner put a donut pillow around him and he loves it so much he won't let anyone take it off. 13/10 https:…                             \n",
       "439   This is Oliver. He has dreams of being a service puppo so he can help his owner. 13/10 selfless af\\n\\nmake it happen:\\nhttps://t.co/f5WMsx0a9K https://t.co/6lJz0DKZIb   \n",
       "1648  This is Buddy. He's gaining strength. Currently an F4 tornado with wind speeds up to 260mph. Very devastating. 9/10 https://t.co/qipZbshNsR                              \n",
       "\n",
       "      retweeted_status_id  retweeted_status_user_id  \\\n",
       "541   7.833346e+17         4.196984e+09               \n",
       "1502 NaN                  NaN                         \n",
       "286   7.838400e+17         4.196984e+09               \n",
       "439  NaN                  NaN                         \n",
       "1648 NaN                  NaN                         \n",
       "\n",
       "     retweeted_status_timestamp  \\\n",
       "541   2016-10-04 15:55:06 +0000   \n",
       "1502  NaN                         \n",
       "286   2016-10-06 01:23:05 +0000   \n",
       "439   NaN                         \n",
       "1648  NaN                         \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                        expanded_urls  \\\n",
       "541   https://twitter.com/dog_rates/status/783334639985389568/photo/1,https://twitter.com/dog_rates/status/783334639985389568/photo/1,https://twitter.com/dog_rates/status/783334639985389568/photo/1,https://twitter.com/dog_rates/status/783334639985389568/photo/1,https://twitter.com/dog_rates/status/783334639985389568/photo/1,https://twitter.com/dog_rates/status/783334639985389568/photo/1   \n",
       "1502  https://vine.co/v/iiI3wmqXYmA                                                                                                                                                                                                                                                                                                                                                                     \n",
       "286   https://twitter.com/dog_rates/status/783839966405230592/photo/1,https://twitter.com/dog_rates/status/783839966405230592/photo/1,https://twitter.com/dog_rates/status/783839966405230592/photo/1                                                                                                                                                                                                   \n",
       "439   https://www.gofundme.com/servicedogoliver,https://twitter.com/dog_rates/status/819952236453363712/photo/1                                                                                                                                                                                                                                                                                         \n",
       "1648  https://twitter.com/dog_rates/status/683773439333797890/photo/1                                                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "      rating_numerator  rating_denominator    name doggo floofer pupper  puppo  \n",
       "541   12                10                  Dave    None  None    None   None   \n",
       "1502  13                10                  Teddy   None  None    None   None   \n",
       "286   13                10                  Riley   None  None    None   None   \n",
       "439   13                10                  Oliver  None  None    None   puppo  \n",
       "1648  9                 10                  Buddy   None  None    None   None   "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the twitter-archive-enhanced.csv\n",
    "#Reading a sample to have a feel of the data\n",
    "df_1 = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "df_archive = df_1.copy()\n",
    "df_archive.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Request to programatically download  image_predictions.tsv from given url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>822872901745569793</td>\n",
       "      <td>https://pbs.twimg.com/media/C2tugXLXgAArJO4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Lakeland_terrier</td>\n",
       "      <td>0.196015</td>\n",
       "      <td>True</td>\n",
       "      <td>Labrador_retriever</td>\n",
       "      <td>0.160329</td>\n",
       "      <td>True</td>\n",
       "      <td>Irish_terrier</td>\n",
       "      <td>0.069126</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>786036967502913536</td>\n",
       "      <td>https://pbs.twimg.com/media/CtKHLuCWYAA2TTs.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>golden_retriever</td>\n",
       "      <td>0.993830</td>\n",
       "      <td>True</td>\n",
       "      <td>cocker_spaniel</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>True</td>\n",
       "      <td>Great_Pyrenees</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>878776093423087618</td>\n",
       "      <td>https://pbs.twimg.com/media/DDIKMXzW0AEibje.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Italian_greyhound</td>\n",
       "      <td>0.734684</td>\n",
       "      <td>True</td>\n",
       "      <td>whippet</td>\n",
       "      <td>0.150487</td>\n",
       "      <td>True</td>\n",
       "      <td>Ibizan_hound</td>\n",
       "      <td>0.039725</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>852226086759018497</td>\n",
       "      <td>https://pbs.twimg.com/ext_tw_video_thumb/852223481894903808/pu/img/JWNq40ol4DXvHoUP.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>prison</td>\n",
       "      <td>0.352793</td>\n",
       "      <td>False</td>\n",
       "      <td>dishwasher</td>\n",
       "      <td>0.110723</td>\n",
       "      <td>False</td>\n",
       "      <td>file</td>\n",
       "      <td>0.094112</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>671561002136281088</td>\n",
       "      <td>https://pbs.twimg.com/media/CVHdK-7WwAAsuyc.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Gordon_setter</td>\n",
       "      <td>0.469373</td>\n",
       "      <td>True</td>\n",
       "      <td>black-and-tan_coonhound</td>\n",
       "      <td>0.270893</td>\n",
       "      <td>True</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>0.153233</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id  \\\n",
       "1744  822872901745569793   \n",
       "1510  786036967502913536   \n",
       "2010  878776093423087618   \n",
       "1905  852226086759018497   \n",
       "313   671561002136281088   \n",
       "\n",
       "                                                                                      jpg_url  \\\n",
       "1744  https://pbs.twimg.com/media/C2tugXLXgAArJO4.jpg                                           \n",
       "1510  https://pbs.twimg.com/media/CtKHLuCWYAA2TTs.jpg                                           \n",
       "2010  https://pbs.twimg.com/media/DDIKMXzW0AEibje.jpg                                           \n",
       "1905  https://pbs.twimg.com/ext_tw_video_thumb/852223481894903808/pu/img/JWNq40ol4DXvHoUP.jpg   \n",
       "313   https://pbs.twimg.com/media/CVHdK-7WwAAsuyc.jpg                                           \n",
       "\n",
       "      img_num                 p1   p1_conf  p1_dog                       p2  \\\n",
       "1744  1        Lakeland_terrier   0.196015  True    Labrador_retriever        \n",
       "1510  1        golden_retriever   0.993830  True    cocker_spaniel            \n",
       "2010  2        Italian_greyhound  0.734684  True    whippet                   \n",
       "1905  1        prison             0.352793  False   dishwasher                \n",
       "313   1        Gordon_setter      0.469373  True    black-and-tan_coonhound   \n",
       "\n",
       "       p2_conf  p2_dog              p3   p3_conf  p3_dog  \n",
       "1744  0.160329  True    Irish_terrier   0.069126  True    \n",
       "1510  0.003143  True    Great_Pyrenees  0.000917  True    \n",
       "2010  0.150487  True    Ibizan_hound    0.039725  True    \n",
       "1905  0.110723  False   file            0.094112  False   \n",
       "313   0.270893  True    Rottweiler      0.153233  True    "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a variable containing the url from which we want to request Data\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "#save the requested url in a file named image_predictions.tsv\n",
    "with open('image_predictions.tsv', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "#import the file in a dataframe with pandas\n",
    "df_2 = pd.read_csv('image_predictions.tsv', delimiter='\\t')\n",
    "image_df = df_2.copy()\n",
    "image_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrivieng Data from Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authentication with twitter API using \n",
    "auth = tweepy.OAuthHandler('p2BWpeoQLwgyO9HNBAeYAwSAu' ,'fRnHPR225sL9lQtgvANK3tZMVh3TrwkPw6TkRqHMsY3EWgHW7y')\n",
    "auth.set_access_token('1090421968623390720-cenMGb4xHFMnuyBXBZuLH4QuCRIaKZ','XMGq0HEaSWrSXVQMT080gkPToTx6HwuH0X4AWCaVGlR4R')\n",
    "\n",
    "#create api to create to twitter with credetianls\n",
    "api = tweepy.API(auth , wait_on_rate_limit = True, wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting tweet ids from archive_df in a list. the list will be used to query twitter api for more data\n",
    "tweet_ids = df_archive['tweet_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n"
     ]
    }
   ],
   "source": [
    "# #looping through the list of tweet_ids to query to twitter API, saving the changes to tweet.json file\n",
    "# with open('tweet_json.txt', 'a', encoding='utf8') as file:\n",
    "#     for tweet_id in tweet_ids:\n",
    "#         try:\n",
    "#             tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "#             json.dump(tweet._json, file)\n",
    "#             file.write('\\n')\n",
    "#         except tweepy.TweepError as e:\n",
    "#                 print (e.reason)\n",
    "#                 #print (e.api_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the api data from json file to panda dataframe\n",
    "api_data = []\n",
    "\n",
    "with open('tweet_json.txt') as json_file:\n",
    "    for line in json_file:\n",
    "        try: \n",
    "            json_data = json.loads(line)\n",
    "            api_data.append(json_data)\n",
    "        except:\n",
    "            continue\n",
    "df_3 = pd.DataFrame(api_data)\n",
    "api_data_df = df_3.copy()\n",
    "api_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting twitter_ids that where not found in the API \n",
    "df_archive.tweet_id.count() - api_data_df.id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# As specified in the project instructions, I am going to only keep retweet_count and liked tweet(favorite count)\n",
    "twitter_api_df = api_data_df[['id', 'retweet_count', 'favorite_count']]\n",
    "twitter_api_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data \n",
    "In this section we are going to assess the 3 datasets that we have collected for issues to fix. we will identify and list them. those issues will be fixed in a later section. \n",
    "we will both assess the datasets visually and programatically using pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 1: Twitter Archive\n",
    "This is the twitter archive data from \"twitter-archive-enhanced.csv\" file. we imported it in a dataframe called df_archive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality Issues: \n",
    "while visually assessing the dataset visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.name.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_archive.name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['floofer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['doggo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['pupper'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['puppo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_archive.loc[(df_archive[['doggo', 'floofer', 'pupper', 'puppo']] != 'None').sum(axis=1) > 1]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['rating_numerator'].count(), df_archive['rating_numerator'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['rating_numerator'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['rating_denominator'].count(), df_archive['rating_denominator'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['rating_denominator'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2: Image Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets 3: Data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_api_df.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_api_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_api_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_api_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_api_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues Found: \n",
    "\n",
    "#### Data Quality Issues:\n",
    "\n",
    "1. In the twitter archive file, (from the csv) I doubt that 745 dogs's name is None. I would tend to consider this as missing value. this is a quality issue and should be replaced by NA for missing value. \n",
    "\n",
    "2. the columns doggo , floofer, pupper and puppo which are dogs stage have the value None (python equivalent of NA). which is an issue because when doing programatic assessment with pandas, its shows no null values\n",
    "\n",
    "\n",
    "3. in_reply_to_status_id  with 78 non-null float64 has too many missing values, it would be hard to do any analysis with so many missing values. \n",
    "\n",
    "4.  in_reply_to_user_id  with only 78 non-null float64 has too many missing values, it would be hard to do any analysis with this column, to drop\n",
    "\n",
    "\n",
    "5. retweeted_status_user_id  has too many  missing values    181 non-null float64\n",
    "\n",
    "6. retweeted_status_timestamp    has too many missing values 181 non-null object\n",
    "\n",
    "7. retweeted_status_timestamp    with only 181 non-null object has too many  missing values to be useful. The column will be dropped. \n",
    "8. 19 tweet_id failed while making taking data from the twitter api. \n",
    "\n",
    "9. I also doubt that  55 dogs are really called \"a\". This might be a typo. \n",
    "\n",
    "10. rename the name in the columns for image predictions. from p1 to breed_prediction_1\n",
    "\n",
    "11. merge the archive dataset and api dataset based on tweet_ids\n",
    "\n",
    "12. Incorrect values in rating numerators\n",
    "\n",
    "13. ID fields need to be stored as strings since no numerical operations needs to be applied on them\n",
    "\n",
    "#### Tidiness Issues: \n",
    "\n",
    "1. move the image and breed_prediction columns from image_df to new_df\n",
    "2. Dog stages needs to be combined in one column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning \n",
    "\n",
    "## Quality Issues\n",
    "Quality issues are cleaned in the order used to list them in the assessement part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define \n",
    "Quality issue No 1:<br>\n",
    "In the df_archive file, in the column name, replace value None by NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "archive_1 = df_archive.copy()\n",
    "df_archive['name'].replace('None', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "df_archive.query('name == \"None\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define \n",
    "Quality issue No2: <br>\n",
    "The columns doggo , floofer, pupper and puppo which are dogs stage have the value None.I am going to replace None with NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing python None by pandas NA\n",
    "df_archive['doggo'].replace('None', np.nan, inplace=True)\n",
    "df_archive['floofer'].replace('None', np.nan, inplace=True)\n",
    "df_archive['pupper'].replace('None', np.nan, inplace=True)\n",
    "df_archive['puppo'].replace('None', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.loc[(df_archive[['doggo', 'floofer', 'pupper', 'puppo']] == 'None').sum(axis=1) >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Quality Issues No 3,4,5,6,7. <br>\n",
    "removing columns that would be hard to use due to too many missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.drop(['in_reply_to_status_id'], inplace=True, axis=1)\n",
    "df_archive.drop(['in_reply_to_user_id'], inplace=True, axis=1)\n",
    "df_archive.drop(['retweeted_status_id'], inplace=True, axis=1)\n",
    "df_archive.drop(['retweeted_status_user_id'], inplace=True, axis=1)\n",
    "df_archive.drop(['retweeted_status_timestamp'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Quality Issue No 8: <br>\n",
    "Removing the tweet_id present in the archive file but that where not found in the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting twitter_ids that where not found in the API \n",
    "df_archive.tweet_id.count() - api_data_df.id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keeping successful tweet_ids\n",
    "df_archive_new = df_archive.copy()\n",
    "df_archive_new = df_archive[df_archive.tweet_id.isin(twitter_api_df.id.tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking \n",
    "df_archive_new.tweet_id.count() - api_data_df.id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Quality Issue No 9: <br>\n",
    "From archive_df, now archive_df_new, remove from the name's column the name a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_new['name'].replace('a', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "df_archive_new.query('name == \"a\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Quality Issue No 10: <br>\n",
    "rename the name in the columns for image predictions. from p1 to breed_prediction_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the name in the columns for image predictions. from p1 to breed_prediction\n",
    "image_df.rename(columns={'p1':'breed_prediction'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing to verify name change\n",
    "image_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Quality issue No 11: <br>\n",
    "merge the archive dataset and api dataset based on tweet_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the archive dataset and twitter_api_df dataset based on common tweet_ids\n",
    "new_df = df_archive_new.copy()\n",
    "new_df = df_archive_new.merge(twitter_api_df,how='inner', left_on='tweet_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since columns tweet_id and id contains the same information, drop one of them\n",
    "new_df.drop(['id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retweet_count and favorite_count added\n",
    "new_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Quality issue 12: <br>\n",
    "correct the values in rating numerators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a tweet where the rating numerator did not consider the decimal value\n",
    "df_archive.query('tweet_id == 786709082849828864')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a regular expression to include decimal values in the numerator as well as the denominator\n",
    "ratings = new_df.text.str.extract('((?:\\d+\\.)?\\d+)\\/(\\d+\\.?\\d)', expand=True)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.columns = ['rating_numerator', 'rating_denominator']\n",
    "ratings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of the archive dataframe before dropping the old ratings numeratior and denominator columns\n",
    "new_df  = new_df.copy()\n",
    "new_df.drop(['rating_numerator'], inplace=True, axis=1)\n",
    "new_df.drop(['rating_denominator'], inplace=True, axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#merging the ratings object obtained from exctracting string with regular expression\n",
    "new_df = pd.merge(new_df, ratings, left_index=True, right_index=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking the same tweet_id after including new columns\n",
    "new_df.query('tweet_id == 786709082849828864')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking numerator values\n",
    "new_df.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the numbers of tweet where the denominator is not equal to 10\n",
    "(new_df.shape[0])-2316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking values which seems very high so that I can adjust the regular expression\n",
    "pd.set_option('display.max_colwidth', -1) \n",
    "new_df.query('rating_numerator == \"15\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking values which seems very high so that I can adjust the regular expression\n",
    "#it's might be a typo or something else, in any case from the text column, the rating is actually 420\n",
    "pd.set_option('display.max_colwidth', -1) \n",
    "new_df.query('rating_numerator == \"420\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking values which seems very high so that I can adjust the regular expression\n",
    "pd.set_option('display.max_colwidth', -1) \n",
    "new_df.query('rating_numerator == \"1776\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[[\"rating_numerator\", \"rating_denominator\"]] = new_df[[\"rating_numerator\", \"rating_denominator\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a query to find all tweet with a rating above 16\n",
    "pd.set_option('display.max_colwidth', -1) \n",
    "strange_numerator = new_df[(new_df['rating_numerator'] >= 16)]\n",
    "strange_numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_numerator.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_numerator.tweet_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the numerator don't seems right, and they are only 21, I am going to delete them from the dataframe\n",
    "archive_new = new_df.copy()\n",
    "new_df = new_df[~new_df.tweet_id.isin(strange_numerator.tweet_id.tolist())]\n",
    "#df_archive.drop(['in_reply_to_status_id'], inplace=True, axis=1)\n",
    "new_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the shape of the new dataframe is the same \n",
    "archive_new.shape[0] - new_df.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Quality issue  No 13:<br>\n",
    "IDs in the archive dataframe needs to be converted to string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['tweet_id'] = new_df['tweet_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidiness Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "make one column out of doggo, floofer, pupper, puppo. the new column is dog_stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if any dog has more than one stage\n",
    "new_df.loc[(new_df[['doggo', 'floofer', 'pupper', 'puppo']] ).sum(axis=1) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['dog_stages'] = new_df['text'].str.extract('(doggo|floofer|pupper|puppo)', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping now useless floofer, pupper, doggo and puppo columns\n",
    "new_df.drop(['doggo'], inplace=True, axis=1)\n",
    "new_df.drop(['floofer'], inplace=True, axis=1)\n",
    "new_df.drop(['pupper'], inplace=True, axis=1)\n",
    "new_df.drop(['puppo'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "move the image and breed_prediction columns from image_df to new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the image and breed_prediction columns from image_df to new_df\n",
    "image_df_new = image_df[['tweet_id', 'jpg_url', 'breed_prediction']]\n",
    "\n",
    "#converting tweet_id column to string\n",
    "image_df_new['tweet_id'] = image_df_new['tweet_id'].astype(str)\n",
    "\n",
    "image_df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df = new_df(image_df_new,how='inner', on='tweet_id')\n",
    "final_df = new_df.merge(image_df_new, how='inner', on='tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image and breed prediction are added\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Cleaned Dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the clean dataframe to a csv file \n",
    "final_df.to_csv('twitter_archive_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ##WeRateDog Clean Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most popular Names in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts for each name\n",
    "final_df.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common Type of Breed (from prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "popular_breed = final_df.breed_prediction.value_counts()\n",
    "breed=popular_breed.head(10)\n",
    "breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_type = ('Golden Retriever', 'Labrador Retriever', 'Pembroke', 'Chihuahua', 'pug', 'chow', 'samoyed', 'Toy poodle', 'Pomeranian', 'Cocker Spaniel')\n",
    "breed_count = [148, 97, 87, 81, 57, 44, 42, 39, 38,30]\n",
    " \n",
    "fig,ax = plt.subplots(figsize = (12,8))\n",
    "ax.barh(breed_type, breed_count, alpha=0.5)\n",
    "plt.yticks(breed_type)\n",
    "plt.xlabel('Number of Dogs')\n",
    "plt.title('10 most popular Dog Breed (from Predictions)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Average number of likes is 8408 per tweet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.favorite_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Average each tweet is retweeted 2799 times! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.retweet_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The average rating is 10.66/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.rating_numerator.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights\n",
    "\n",
    "### Most Popular Names:\n",
    "\n",
    "* Lucy \n",
    "* Penny \n",
    "* Charlie\n",
    "* Oliver \n",
    "* Cooper\n",
    "* Tucker  \n",
    "\n",
    "All names on this list has 10 occurences each. \n",
    "\n",
    "### Popular Dog Breed: \n",
    "\n",
    "The Golden Retriever is bar far the most frequent dog breed(150 times). followed by the Labrador Retriever (100 times). \n",
    "\n",
    "###  The Average number of likes is 8385 in the dataset\n",
    "\n",
    "The average tweet in this dataset has favorite_count of 8385 in average. which quite high, meaning that in average, many people enjoy the post. the most liked tweet being at 163924 likes. \n",
    "\n",
    "### In Average each tweet is retweeted 2792 times!\n",
    "\n",
    "In average a WeRateDogs tweet is retweeted 2792 times. the most retweeted tweet being at 83381 according to the data we have.\n",
    "\n",
    "### The average rating is 12.26/10\n",
    "The average Rating for the dogs in this dataset is 12.26/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and References: \n",
    "\n",
    "* Requests Official Documentation: http://docs.python-requests.org/en/master/user/quickstart/#response-content\n",
    "* Dowloading files using Requests: https://www.geeksforgeeks.org/downloading-files-web-using-python/\n",
    "* Importing tsv file: https://www.kaggle.com/tinoswe/split-python-dataframe\n",
    "* Using Tweepy to query twitter API : http://docs.tweepy.org/en/3.7.0/getting_started.html\n",
    "* Retrieving Data from Twitter API: https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html <br>\n",
    "https://github.com/SThornewillvE/Udacity-Project---Data-Wrangling/blob/master/wrangling-act.ipynb <br>\n",
    "https://github.com/S-Tabor/udacity-data-wrangling-project/blob/master/wrangle_project_final.ipynb <br>\n",
    "https://github.com/xhlow/dand-t2-p3-data-wrangling/blob/master/wrangle_act.ipynb\n",
    "* Matplotlib Bar chart : https://pythonspot.com/matplotlib-bar-chart/\n",
    "* merging dataframe on index : https://stackoverflow.com/questions/40468069/merge-two-dataframes-by-index\n",
    "* regular expressions: https://www.youtube.com/watch?v=e0xL9o5VibU\n",
    "* reverse of is: https://gist.github.com/aswad32/b580ef0311878c7bf710c835bba4f35b\n",
    "* pandas to_numeric: https://stackoverflow.com/questions/15891038/change-data-type-of-columns-in-pandas\n",
    "* seeing full  pandas's column text/content:https://stackoverflow.com/questions/25351968/how-to-display-full-non-truncated-dataframe-information-in-html-when-convertin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the End, Thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
